{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LUCA AMBROSIO\n",
    "### HOMEWORK 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This homework is based on the wine quality classification research paper and\n",
    "dataset shared on the course page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What to do\n",
    "The homework consists in building a classification model which is able to predict the\n",
    "quality of the wine (multiclass classification) based on its physicochemical values.\n",
    "\n",
    "## Approach\n",
    "\n",
    "The idea is to apply different approaches and evaluate them, in terms of Accuracy,\n",
    "Precision-per class and Recall-per class. You can apply the hold-out validation\n",
    "methodology, selecting randomly 20% of a dataset for testing. Per each approach,\n",
    "plot also the Confusion Matrix and make some reasoning over it. Make a conclusion,\n",
    "proposing your best model.\n",
    "\n",
    "## Suggestions\n",
    "\n",
    "Use Decision Tree and Random Forest classification algorithms. Try building\n",
    "different models and tune the algorithms parameters, in order to increase the\n",
    "performances of the trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I import the libraries needed to perform the homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "import sklearn.ensemble\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it was decided to combine the datasets in order to have an example of more heterogeneous data to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"winequality-white.csv\", error_bad_lines=False, sep = ';')\n",
    "data2 = pd.read_csv(\"winequality-red.csv\", error_bad_lines=False,  sep = ';')\n",
    "data1[\"wine_type\"]= 1   #white\n",
    "data2[\"wine_type\"]= 0   #red\n",
    "merged = pd.concat([data1,data2], ignore_index=True, sort=False)\n",
    "#print(merged.head(50))\n",
    "#train and test division\n",
    "x = merged[[\"fixed acidity\",\"volatile acidity\",\"citric acid\",\"residual sugar\",\"chlorides\",\"free sulfur dioxide\",\"total sulfur dioxide\",\"density\",\"pH\",\"sulphates\",\"alcohol\",\"wine_type\"]]\n",
    "y = merged[\"quality\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6497, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>wine_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.70</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.90</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.90</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.16</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.045</td>\n",
       "      <td>30.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.9949</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.47</td>\n",
       "      <td>9.6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.70</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.044</td>\n",
       "      <td>28.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.9938</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.45</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.033</td>\n",
       "      <td>11.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.56</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8.6</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.40</td>\n",
       "      <td>4.20</td>\n",
       "      <td>0.035</td>\n",
       "      <td>17.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.9947</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.53</td>\n",
       "      <td>9.7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.040</td>\n",
       "      <td>16.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.9920</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.63</td>\n",
       "      <td>10.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.044</td>\n",
       "      <td>48.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0.9912</td>\n",
       "      <td>3.54</td>\n",
       "      <td>0.52</td>\n",
       "      <td>12.4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8.3</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.62</td>\n",
       "      <td>19.25</td>\n",
       "      <td>0.040</td>\n",
       "      <td>41.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1.0002</td>\n",
       "      <td>2.98</td>\n",
       "      <td>0.67</td>\n",
       "      <td>9.7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.032</td>\n",
       "      <td>28.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.9914</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.55</td>\n",
       "      <td>11.4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.046</td>\n",
       "      <td>30.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.36</td>\n",
       "      <td>9.6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.029</td>\n",
       "      <td>29.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.9892</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.39</td>\n",
       "      <td>12.8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.033</td>\n",
       "      <td>17.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>0.9917</td>\n",
       "      <td>3.12</td>\n",
       "      <td>0.53</td>\n",
       "      <td>11.3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.14</td>\n",
       "      <td>7.50</td>\n",
       "      <td>0.044</td>\n",
       "      <td>34.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0.9955</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0             7.0              0.27         0.36           20.70      0.045   \n",
       "1             6.3              0.30         0.34            1.60      0.049   \n",
       "2             8.1              0.28         0.40            6.90      0.050   \n",
       "3             7.2              0.23         0.32            8.50      0.058   \n",
       "4             7.2              0.23         0.32            8.50      0.058   \n",
       "5             8.1              0.28         0.40            6.90      0.050   \n",
       "6             6.2              0.32         0.16            7.00      0.045   \n",
       "7             7.0              0.27         0.36           20.70      0.045   \n",
       "8             6.3              0.30         0.34            1.60      0.049   \n",
       "9             8.1              0.22         0.43            1.50      0.044   \n",
       "10            8.1              0.27         0.41            1.45      0.033   \n",
       "11            8.6              0.23         0.40            4.20      0.035   \n",
       "12            7.9              0.18         0.37            1.20      0.040   \n",
       "13            6.6              0.16         0.40            1.50      0.044   \n",
       "14            8.3              0.42         0.62           19.25      0.040   \n",
       "15            6.6              0.17         0.38            1.50      0.032   \n",
       "16            6.3              0.48         0.04            1.10      0.046   \n",
       "17            6.2              0.66         0.48            1.20      0.029   \n",
       "18            7.4              0.34         0.42            1.10      0.033   \n",
       "19            6.5              0.31         0.14            7.50      0.044   \n",
       "\n",
       "    free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                  45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                  14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                  30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                  47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                  47.0                 186.0   0.9956  3.19       0.40   \n",
       "5                  30.0                  97.0   0.9951  3.26       0.44   \n",
       "6                  30.0                 136.0   0.9949  3.18       0.47   \n",
       "7                  45.0                 170.0   1.0010  3.00       0.45   \n",
       "8                  14.0                 132.0   0.9940  3.30       0.49   \n",
       "9                  28.0                 129.0   0.9938  3.22       0.45   \n",
       "10                 11.0                  63.0   0.9908  2.99       0.56   \n",
       "11                 17.0                 109.0   0.9947  3.14       0.53   \n",
       "12                 16.0                  75.0   0.9920  3.18       0.63   \n",
       "13                 48.0                 143.0   0.9912  3.54       0.52   \n",
       "14                 41.0                 172.0   1.0002  2.98       0.67   \n",
       "15                 28.0                 112.0   0.9914  3.25       0.55   \n",
       "16                 30.0                  99.0   0.9928  3.24       0.36   \n",
       "17                 29.0                  75.0   0.9892  3.33       0.39   \n",
       "18                 17.0                 171.0   0.9917  3.12       0.53   \n",
       "19                 34.0                 133.0   0.9955  3.22       0.50   \n",
       "\n",
       "    alcohol  quality  wine_type  \n",
       "0       8.8        6          1  \n",
       "1       9.5        6          1  \n",
       "2      10.1        6          1  \n",
       "3       9.9        6          1  \n",
       "4       9.9        6          1  \n",
       "5      10.1        6          1  \n",
       "6       9.6        6          1  \n",
       "7       8.8        6          1  \n",
       "8       9.5        6          1  \n",
       "9      11.0        6          1  \n",
       "10     12.0        5          1  \n",
       "11      9.7        5          1  \n",
       "12     10.8        5          1  \n",
       "13     12.4        7          1  \n",
       "14      9.7        5          1  \n",
       "15     11.4        7          1  \n",
       "16      9.6        6          1  \n",
       "17     12.8        8          1  \n",
       "18     11.3        6          1  \n",
       "19      9.5        5          1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "[xTrain, xTest] = train_test_split(x, test_size=0.2, random_state=42) # la dimensione del test set è il 20% del dataset\n",
    "[yTrain, yTest] = train_test_split(y, test_size=0.2, random_state=42) # la dimensione del test set è il 20% del dataset \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wine_tree.pdf'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Decision Tree\n",
    "from sklearn import tree\n",
    "#train the tree\n",
    "classifier = tree.DecisionTreeClassifier()\n",
    "classifier.fit(xTrain, yTrain)\n",
    "\n",
    "import graphviz\n",
    "wine_tree = tree.export_graphviz(classifier, out_file=None, \n",
    "                         feature_names=xTrain.columns,  \n",
    "                         class_names=yTrain.unique().astype(str),  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)  \n",
    "graph = graphviz.Source(wine_tree) \n",
    "graph.render(\"wine_tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red Wine quality preciction model Accuracy: 0.6015384615384616\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.24      0.28      0.26        46\n",
      "           5       0.67      0.67      0.67       420\n",
      "           6       0.66      0.64      0.65       579\n",
      "           7       0.52      0.50      0.51       221\n",
      "           8       0.23      0.25      0.24        32\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.60      0.60      0.60      1300\n",
      "   macro avg       0.33      0.33      0.33      1300\n",
      "weighted avg       0.61      0.60      0.61      1300\n",
      "\n",
      "[[  0   1   1   0   0   0   0]\n",
      " [  0  13  14  15   4   0   0]\n",
      " [  7  19 282  96  14   2   0]\n",
      " [  3  15 110 369  73   9   0]\n",
      " [  2   6  14  73 110  16   0]\n",
      " [  0   0   2  10  11   8   1]\n",
      " [  0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luca\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Luca\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Luca\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "y_hat = classifier.predict(xTest)\n",
    "labels_prob_predicted_red = classifier.predict_proba(xTest)\n",
    "#accuracy\n",
    "print(\"Red Wine quality preciction model Accuracy: {}\".format(metrics.accuracy_score(yTest, y_hat)))\n",
    "#precision and recall per class\n",
    "print(metrics.classification_report(yTest, y_hat))\n",
    "\n",
    "cm = confusion_matrix(yTest, y_hat)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=15,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=1.0, n_estimators=30, random_state=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = AdaBoostClassifier(DecisionTreeClassifier(max_depth=15),n_estimators=30)\n",
    "classifier.fit(xTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   1   1   0   0]\n",
      " [  0   8  19  18   1   0]\n",
      " [  0   1 312 107   0   0]\n",
      " [  0   0  95 447  35   2]\n",
      " [  0   0   8 106 105   2]\n",
      " [  0   0   1  15   8   8]]\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(xTest)\n",
    "cm = confusion_matrix(yTest, predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.676923076923077\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy: {}\".format(metrics.accuracy_score(yTrain, classifier.predict(xTrain))))\n",
    "print(\"Test Accuracy: {}\".format(metrics.accuracy_score(yTest, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red Wine quality preciction model Accuracy: 0.676923076923077\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.89      0.17      0.29        46\n",
      "           5       0.72      0.74      0.73       420\n",
      "           6       0.64      0.77      0.70       579\n",
      "           7       0.70      0.48      0.57       221\n",
      "           8       0.67      0.25      0.36        32\n",
      "\n",
      "   micro avg       0.68      0.68      0.68      1300\n",
      "   macro avg       0.60      0.40      0.44      1300\n",
      "weighted avg       0.69      0.68      0.66      1300\n",
      "\n",
      "[[  0   0   1   1   0   0]\n",
      " [  0   8  19  18   1   0]\n",
      " [  0   1 312 107   0   0]\n",
      " [  0   0  95 447  35   2]\n",
      " [  0   0   8 106 105   2]\n",
      " [  0   0   1  15   8   8]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luca\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Luca\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Luca\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "labels_prob_predicted_red = classifier.predict_proba(xTest)\n",
    "#accuracy\n",
    "print(\"Red Wine quality preciction model Accuracy: {}\".format(metrics.accuracy_score(yTest, predictions)))\n",
    "#precision and recall per class\n",
    "print(metrics.classification_report(yTest, predictions))\n",
    "\n",
    "cm = confusion_matrix(yTest, predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aumentando max_depth abbiamo che la nostra accuratezza del modello cresce mentre aumentando il numero di estimentori notimo che il tempo\n",
    "di esecuzione cresce di molto ma non si ha un consistente aumento di accuratezza del modello\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Test Accuracy:  0.6838461538461539\n",
      "Train Accuracy:  0.9372715027900712\n"
     ]
    }
   ],
   "source": [
    "\n",
    "[xTrain, xTest] = train_test_split(x, test_size=0.2, random_state=55) # la dimensione del test set è il 20% del dataset\n",
    "[yTrain, yTest] = train_test_split(y, test_size=0.2, random_state=55) # la dimensione del test set è il 20% del dataset \n",
    "\n",
    "clf = sklearn.ensemble.RandomForestClassifier(n_estimators=100)\n",
    "print(clf)\n",
    "clf.fit(xTrain, yTrain)\n",
    "\n",
    "yhat_te = clf.predict(xTest)\n",
    "yscores_te = clf.predict_proba(xTest)\n",
    "\n",
    "print(\"Test Accuracy: \",np.mean(yTest==yhat_te))\n",
    "print(\"Train Accuracy: \",np.mean(classifier.predict(xTrain)==yTrain))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red Wine quality preciction model Accuracy: 0.6838461538461539\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.83      0.10      0.18        50\n",
      "           5       0.72      0.74      0.73       436\n",
      "           6       0.64      0.79      0.71       549\n",
      "           7       0.73      0.50      0.60       220\n",
      "           8       0.82      0.34      0.48        41\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.68      0.68      0.68      1300\n",
      "   macro avg       0.54      0.35      0.39      1300\n",
      "weighted avg       0.70      0.68      0.67      1300\n",
      "\n",
      "[[  0   0   1   2   0   0   0]\n",
      " [  0   5  31  13   1   0   0]\n",
      " [  0   1 324 107   4   0   0]\n",
      " [  0   0  85 435  27   2   0]\n",
      " [  0   0   5 103 111   1   0]\n",
      " [  0   0   1  17   9  14   0]\n",
      " [  0   0   0   0   1   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luca\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Luca\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Luca\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "labels_prob_predicted_red = classifier.predict_proba(xTest)\n",
    "#accuracy\n",
    "print(\"Red Wine quality preciction model Accuracy: {}\".format(metrics.accuracy_score(yTest, yhat_te)))\n",
    "#precision and recall per class\n",
    "print(metrics.classification_report(yTest,yhat_te))\n",
    "\n",
    "cm = confusion_matrix(yTest, yhat_te)\n",
    "print(cm)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
